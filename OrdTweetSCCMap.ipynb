{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\r\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\r\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\r\n",
    "from ekphrasis.dicts.emoticons import emoticons\r\n",
    "import spacy\r\n",
    "nlp1 = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\r\n",
    "from spacy.lang.en import English\r\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\r\n",
    "import nltk\r\n",
    "from nltk.stem import PorterStemmer\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem.snowball import SnowballStemmer\r\n",
    "import re\r\n",
    "import sys\r\n",
    "import warnings\r\n",
    "import tkinter as tk\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "ps  = SnowballStemmer(\"english\")\r\n",
    "from tkinter import messagebox\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "wnl = WordNetLemmatizer()\r\n",
    "import pickle\r\n",
    "\r\n",
    "\r\n",
    "print(\"starting setup\")\r\n",
    "ekphrasis_process = TextPreProcessor(\r\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\r\n",
    "        'time', 'url', 'date', 'number'],\r\n",
    "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\r\n",
    "        'emphasis', 'censored'},\r\n",
    "    fix_html=True, \r\n",
    "    segmenter=\"twitter\", \r\n",
    "    corrector=\"twitter\", \r\n",
    "    unpack_hashtags=True,  \r\n",
    "    unpack_contractions=True, \r\n",
    "    spell_correct_elong=False, \r\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\r\n",
    "    dicts=[emoticons]\r\n",
    ")\r\n",
    "\r\n",
    "print(\"finished setup\")\r\n",
    "\r\n",
    "\r\n",
    "def ekphrasis_word(word):\r\n",
    "\r\n",
    "    return(\" \".join(ekphrasis_process.pre_process_doc(word)))\r\n",
    "\r\n",
    "\r\n",
    "def get_ekphrasis(word):\r\n",
    "    import re\r\n",
    "    b = ekphrasis_word(word)\r\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\r\n",
    "    res = TAG_RE.sub('',b)\r\n",
    "    res = res.rstrip().lstrip()\r\n",
    "    return res    \r\n",
    "\r\n",
    "def spacy_lemmatizer(text):\r\n",
    "    doc = nlp1(text)\r\n",
    "    return (\" \".join([token.lemma_ for token in doc]))\r\n",
    "\r\n",
    "ps = PorterStemmer()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting setup\n",
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "finished setup\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def remove_stopwords(text):\r\n",
    "    \r\n",
    "    nlp = English()\r\n",
    "    my_doc = nlp(text)\r\n",
    "    # Create list of word tokens\r\n",
    "    token_list = []\r\n",
    "    for token in my_doc:\r\n",
    "        token_list.append(token.text)\r\n",
    "    filtered_sentence =[] \r\n",
    "\r\n",
    "    for word in token_list:\r\n",
    "        lexeme = nlp.vocab[word]\r\n",
    "        if lexeme.is_stop == False:\r\n",
    "            filtered_sentence.append(word) \r\n",
    "    res = \" \".join(x for x in filtered_sentence)   \r\n",
    "    return res\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\r\n",
    "if not sys.warnoptions:\r\n",
    "    warnings.simplefilter(\"ignore\")\r\n",
    "def cleanHtml(sentence):\r\n",
    "    cleanr = re.compile('<.*?>')\r\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\r\n",
    "    return cleantext\r\n",
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\r\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\r\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\r\n",
    "    cleaned = cleaned.strip()\r\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\r\n",
    "    return cleaned\r\n",
    "def keepAlpha(sentence):\r\n",
    "    alpha_sent = \"\"\r\n",
    "    for word in sentence.split():\r\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\r\n",
    "        alpha_sent += alpha_word\r\n",
    "        alpha_sent += \" \"\r\n",
    "    alpha_sent = alpha_sent.strip()\r\n",
    "    return alpha_sent\r\n",
    "\r\n",
    "def textinitialpreprocess(def_string):\r\n",
    "    given_string = def_string.lower()\r\n",
    "    given_string = cleanHtml(given_string)\r\n",
    "    given_string = cleanPunc(given_string)\r\n",
    "    given_string = keepAlpha(given_string)\r\n",
    "    return given_string\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "window = tk.Tk()\r\n",
    "window.title(\"SCC Classifier\")\r\n",
    "window.geometry(\"1000x150\")\r\n",
    "copy_s = u\"\\u00A9\" \"Manish Puri\"\r\n",
    "window.configure(background=\"yellow\")\r\n",
    "title = tk.Label( text= \"This tool is developed to map input tweet or ordinances to SCC\", font=(\"Arial\", 10), background=\"yellow\")\r\n",
    "title.grid(column=1, row=0) \r\n",
    "label2 = tk.Label( text= \"Enter tweet/ordinance\", font=(\"Arial\", 10), background=\"yellow\")\r\n",
    "label2.grid(column=0, row=3)\r\n",
    "label4 = tk.Label( text= copy_s  , font=(\"Arial\", 10), background=\"yellow\")\r\n",
    "entry_field1= tk.Entry(width=120, bg = 'light gray', font = 'Calibri', fg = 'green', justify = 'center')\r\n",
    "entry_field1.grid(column=1,row=3)\r\n",
    "dict_phrases =  {'Smart Economy':0, 'Smart Mobility':0, 'Smart Environment':0, 'Smart Governance':0, 'Smart People':0, 'Smart Living':0, 'No Matches':0}\r\n",
    "\r\n",
    "\r\n",
    "def phrase_generator():   \r\n",
    "    economyWordCount    = 0  \r\n",
    "    environmentWordCount= 0\r\n",
    "    governanceWordCount = 0\r\n",
    "    peopleWordCount     = 0\r\n",
    "    mobilityWordCount   = 0 \r\n",
    "    livingWordCount     = 0   \r\n",
    "    file = open('SCC_KB.pkl', 'rb')\r\n",
    "    economy = pickle.load(file)\r\n",
    "    mobility = pickle.load(file)\r\n",
    "    environment = pickle.load(file)\r\n",
    "    governance = pickle.load(file)\r\n",
    "    people = pickle.load(file)\r\n",
    "    living = pickle.load(file)\r\n",
    "\r\n",
    "    economy  = ['accredited', 'asset', 'article50', 'backstop', 'breturn',  'assess', 'barter', 'backstop',  'belong', 'belonging', 'billionaire', 'labour party',  'business', 'dealing', 'financial district', 'business enterprise', 'business organisation', 'business organization', 'business sector' , 'brexit', 'capital', 'capitalism', 'capitalist', 'clientel', 'clientele', 'commercial message', 'commercial', 'commercial-grade', 'commercialize', 'common market', 'consumer',  'consumption', 'cost', 'credit rating', 'credit', 'craft', 'deal', 'department of labor', ' dol ', 'distribution',  'downsizing', 'downswing', 'downturn', 'drudge', 'economy', 'economic', 'economic consumption', 'economic science', 'economic system', 'economical', 'economics', 'economist', 'economy', 'enterprise', 'enterpriser', 'enterprising', 'enterprisingness', 'entrepreneur', ' eu ', 'european union',  'europe', 'european community', 'european economic community', 'expenditure', 'export', 'exportation', 'finance', 'financial', 'fiscal', 'forward looking', ' gdp ', 'global', 'globalisation', 'globalization', 'gross domestic product', 'industrialization', 'industriousness', 'joblessness', 'industry', 'inflation', 'stocks ','infrastructure', 'initiative', 'innovation',  'innovative', 'job', 'labor department', 'labor movement', 'labour party', 'labor',  'labour', 'lien', 'line of work', 'manufacture', 'market', 'market place', 'marketplace', 'mart', 'merchandise', 'moil', 'monetary value', 'occup', 'occupation', 'partnership', 'patronag', 'patronage', 'political economi', 'political economy', 'product', 'production', 'productiveness', 'productivity', 'project', 'proletariat', 'properti', 'joblessness', 'property', 'recognit', 'recognition', 'revenue enhancement', 'revenue', 'profit', 'payable', 'income', 'receivable', 'balance sheet',  'save', 'saving', 'securities industri', 'securities industry', 'sell', 'serv', 'serve', 'servic', 'service', 'social', 'socialism', 'socialist', 'stage busi', 'stage business', 'stock market index', 'substructur', 'substructure', 'swap', 'swop', 'task', 'tax', 'taxat', 'taxation', 'thrifti', 'thriftiness', 'toil', 'trade', 'trade in', 'trade protect', 'trade protection', 'trade union mov', 'trade union movement', 'trade wind', 'travail', 'tribut', 'tribute', 'tug', 'undertak', 'undertaking', 'unemploy', 'unemployment', 'usanc', 'usance', 'wage', 'wages', 'wall street', 'working class', 'yield', 'recession', 'international labour organization', 'homelesness', 'underemployment', 'army of labor', 'welfare', 'startup', 'cash flow', 'debt', 'debit', 'trillion', 'budget', 'accounting', 'hedge fund', 'private equity', 'deindustrialization', 'keynesian', 'eurozone', 'payroll', 'foreclosure', 'deficit', 'borrowing', 'premium', 'compensation',  'stagnation', 'proletariat', 'surplus', 'keynes', 'interest rate', 'federal reserve', 'karl marx', 'denominator', 'beveridge curve', 'bankruptcy', 'great depression', 'monetary policy'    ]\r\n",
    "    mobility   = ['Department of Transportation', 'DoT', 'Speedbump', 'Transportation', 'Visa', 'acceleratorped', 'acceleratorpedal', 'access', 'accessibility', 'auto', 'automobil', 'automobile', 'avail', 'availability', 'availableness', 'berth', 'bicycl', 'bicycle', 'bike', 'bridg', 'bridge', 'bus', 'bus topolog', 'bus topology', 'buse', 'buses', 'cab', 'cable car', 'car', 'caravan', 'carri', 'carry', 'cars', 'channel', 'channelis', 'channelise', 'channelize', 'charabancautobus', 'commut', 'commute', 'commuter', 'commuter train', 'convert', 'convey', 'conveyance', 'cycl', 'cycle', 'cycle rickshaw', 'department of transport', 'department of transportation', 'detour', 'dot', 'double-deck', 'double-decker', 'drive', 'drivers lic', 'drivers licence', 'earthbound', 'elevator car', 'exchang', 'exchange', 'fare', 'flight', 'footer', 'fuel', 'gasped', 'gaspedal', 'gasstat', 'gasstation', 'gondola', 'highway', 'infrastructur', 'infrastructure', 'international flight', 'jalopi', 'jalopy', 'jitney', 'k-turn', 'locomot', 'locomotion', 'lyft', 'map', 'mapping', 'motiv', 'motive', 'motor', 'motorbus', 'motorcar', 'motorcoach', 'omnibus', 'park', 'parking', 'passenger vehicl', 'passenger vehicle', 'pavement', 'pedal', 'pedestrian', 'pedicab', 'plane', 'railcar', 'railroad car', 'railway car', 'road', 'roadwork', 'servicearea', 'ship', 'shipping', 'sidewalk', 'sign', 'sign-languag', 'sign-language', 'signal', 'signaling', 'signalis', 'signalise', 'signalize', 'skyway', 'speed', 'speedbump', 'speeding', 'speedlimit', 'street', 'substructur', 'substructure', 'tape dr', 'tape drive', 'tape transport', 'taxi', 'taxicab', 'thoroughfar', 'thoroughfare', 'thoroughfares', 'traffic', 'trafficaccid', 'trafficaccident', 'trafficdelay', 'transfer', 'transferr', 'transferral', 'transit', 'transmit', 'transport', 'transportation', 'transportation system', 'transpos', 'transpose', 'travel', 'truck', 'trucks', 'uber', 'van', 'vehicl', 'vehicle', 'visa', 'walker', 'way', 'wheel']\r\n",
    "    environment = ['CO', 'CO2', 'DOE', 'Department of Energy', 'Energy', 'Energy Department', 'O3', 'PM10', 'PM2.5', 'Parks', 'VOC', 'Volatileorganiccompound', 'aerat', 'aerate', 'air', 'ash bin', 'ash-bin', 'ashbin', 'ashcan', 'atmospher', 'atmosphere', 'aura', 'aviat', 'aviation', 'basin', 'befoul', 'befoulment', 'bionom', 'bionomic', 'bionomical', 'bionomics', 'breez', 'breeze', 'carbondioxid', 'carbondioxide', 'carbonmonoxid', 'carbonmonoxide', 'catchment area', 'catchment basin', 'co', 'co2', 'coldcock', 'compost', 'constitut', 'constitute', 'contamin', 'contamination', 'defil', 'defilement', 'department of energi', 'department of energy', 'discharg', 'discharge', 'dispos', 'disposal', 'ditch', 'doe', 'drainage area', 'drainage basin', 'drivel', 'dump', 'dumpsit', 'dumpsite', 'dustbin', 'ecolog', 'ecologic', 'ecological', 'ecology', 'emb', 'embed', 'emiss', 'emission', 'energi', 'energy', 'energy depart', 'energy department', 'engraft', 'environ', 'environment', 'environmental sci', 'environmental science', 'environs', 'expel', 'expelling', 'flora', 'food wast', 'food waste', 'free energi', 'free energy', 'garbag', 'garbage', 'garbage can', 'garbage dump', 'gas', 'gaseous st', 'gaseous state', 'gasolen', 'gasolene', 'gasolin', 'gasoline', 'gentle wind', 'glasshous', 'glasshouse', 'green', 'greenhous', 'greenhouse', 'health', 'healthful', 'infrasonicwav', 'infrasonicwave', 'landmark', 'litter', 'natural ga', 'natural gas', 'nitrous', 'nois', 'noise', 'nonpointsourc', 'nonpointsource', 'nurseri', 'nursery', 'o3', 'ozone', 'ozone', 'park', 'parks', 'particulatematt', 'particulatematter', 'permissive wast', 'permissive waste', 'pesticid', 'pesticide', 'petrol', 'plant', 'plant lif', 'plant life', 'pm10', 'pm2.5', 'pointsourc', 'pointsource', 'pollut', 'pollutant', 'pollution', 'protect', 'protection', 'protective cov', 'protective cover', 'protective covering', 'rain', 'reclaim', 'reclaimable', 'recreat', 'recreation', 'recycl', 'recyclable', 'recycle', 'recycling', 'reprocess', 'resourc', 'resource', 'resourcefulness', 'reus', 'reusabl', 'reusable', 'reuse', 'river basin', 'rubbish dump', 'sanit', 'sanitari', 'sanitary', 'sanitation', 'sanitis', 'sanitisation', 'sanitization', 'scrap', 'scraps', 'shelter', 'shit', 'smoke detector', 'solildwast', 'solildwaste', 'stormwat', 'stormwater', 'subdu', 'subdue', 'subsonicwav', 'subsonicwave', 'surround', 'surroundings', 'sustain', 'sustainability', 'sustainable', 'trash barrel', 'trash bin', 'trash can', 'trash dump', 'vent', 'ventil', 'ventilate', 'voc', 'volatileorganiccompound', 'wast', 'waste', 'waste materi', 'waste material', 'waste matt', 'waste matter', 'waste product', 'waste-yard', 'wastebin', 'wastefulness', 'wastewat', 'wastewater', 'wasteyard', 'water part', 'water parting', 'watersh', 'watershed', 'weather', 'wild']\r\n",
    "    governance  = ['Carry Amelia Moore Nation', 'Carry Nation', 'Nation', 'administr', 'administration', 'administrator', 'agenc', 'agency', 'agit', 'agitate', 'ass', 'assault', 'assess', 'attorney', 'author', 'authorities', 'authority', 'body polit', 'body politic', 'budget', 'bureau', 'campaign', 'carry amelia moore n', 'carry amelia moore nation', 'carry n', 'carry nation', 'census', 'certifi', 'certify', 'charge per unit', 'city manag', 'city manager', 'citycouncil', 'commonwealth', 'comptrol', 'comptroller', 'constabulari', 'constabulary', 'control', 'controller', 'convent', 'convention', 'correct', 'correctional', 'countri', 'country', 'crusad', 'crusade', 'decre', 'decree', 'design', 'designation', 'dominion', 'effect', 'effective', 'effici', 'efficient', 'elect', 'elected', 'elective', 'encroach', 'encroachment', 'establish', 'establishment', 'execut', 'executive', 'federal ag', 'federal agency', 'financ', 'finance', 'govern', 'governance', 'governing', 'governing bodi', 'governing body', 'government', 'government act', 'government activity', 'government ag', 'government agency', 'identif', 'identification', 'infract', 'infraction', 'infring', 'infringement', 'intrus', 'intrusion', 'irrever', 'irreverence', 'judicatur', 'judicature', 'law', 'lawyer', 'legisl', 'legislation', 'licenc', 'licence', 'licens', 'license', 'mayor', 'military offic', 'military officer', 'military servic', 'military service', 'misdemeanor', 'misdemeanour', 'movement', 'nation', 'nose count', 'nosecount', 'offic', 'office', 'officehold', 'officeholder', 'officer', 'ordin', 'ordinance', 'organ', 'organis', 'organisation', 'organization', 'part', 'patrol', 'permiss', 'permission', 'permit', 'polic', 'police', 'police forc', 'police force', 'police offic', 'police officer', 'policeman', 'polit', 'political campaign', 'political sci', 'political science', 'politics', 'populac', 'populace', 'power', 'prescript', 'presid', 'presidency', 'presidential term', 'principl', 'principle', 'provis', 'provision', 'public', 'rape', 'ravish', 'ravishment', 'recognit', 'recognition', 'regim', 'regime', 'regul', 'regulation', 'reign', 'republica', 'revenue enhanc', 'revenue enhancement', 'rule', 'ruler', 'sociabl', 'sociable', 'social', 'societ', 'societal', 'spot', 'state', 'surveil', 'surveillance', 'task', 'tax', 'taxat', 'taxation', 'trespass', 'usurp', 'usurpation', 'valu', 'value', 'violat', 'violation', 'world']\r\n",
    "    people = ['Affirmativeaction', 'Atheism', 'BLM', 'EmploymentDiscrimination', 'Feminism', 'LGBT', 'Minoritygroup', 'Righttoeducation', 'acquisit', 'acquisition', 'affirmativeact', 'affirmativeaction', 'atheism', 'belief', 'bisexu', 'bisexual', 'blm', 'citizenri', 'citizenry', 'creativ', 'creative think', 'creative thinking', 'creativeness', 'creativity', 'cultur', 'cultural', 'desegreg', 'desegregation', 'discov', 'discover', 'divers', 'diverseness', 'diversity', 'doctrine', 'employmentdiscrimin', 'employmentdiscrimination', 'encycloped', 'encyclopedism', 'equalityofsex', 'equalityofsexes', 'erudit', 'erudition', 'ethnic', 'ethnical', 'ethnicity', 'exempt', 'exemption', 'faith', 'feel', 'feeling', 'femin', 'feminism', 'freedom', 'gay', 'genderdiscrimin', 'genderdiscrimination', 'heathen', 'heathenish', 'homo', 'human', 'human being', 'human beings', 'impress', 'impression', 'individu', 'individual', 'instruct', 'ism', 'large-groupdoctrin', 'learn', 'learned', 'learnedness', 'learning', 'lesbian', 'lgbt', 'man', 'mass', 'masses', 'memor', 'memoris', 'memorise', 'memorize', 'minor', 'minority', 'minoritygroup', 'mortal', 'multifari', 'multifariousness', 'multitud', 'multitude', 'notion', 'openmind', 'openminded', 'opinion', 'organized religion', 'pagan', 'peopl', 'people', 'philosophi', 'philosophical system', 'philosophy', 'religion', 'religious belief', 'righttoeduc', 'righttoeducation', 'rythm', 'scholarship', 'school of thought', 'small-group', 'studi', 'study', 'teach', 'the great unwash', 'the great unwashed', 'transgend', 'transgender', 'varieti', 'variety', 'woman', 'womanhood']\r\n",
    "    living = ['abid', 'abidance', 'abod', 'abode', 'accultur', 'acculturation', 'act a', 'act as', 'actor', 'aesculapian', 'afford', 'affordable', 'affordablecar', 'affordablecare', 'alcohol', 'alcoholic beverag', 'alcoholic beverage', 'alcoholic drink', 'allow', 'archeological sit', 'archeological site', 'belong', 'belonging', 'belongings', 'brood', 'bug', 'build', 'building', 'bulwark', 'caparison', 'checkup', 'citizen', 'civil', 'civilis', 'civilisation', 'civilization', 'coher', 'coherence', 'coherency', 'cohes', 'cohesion', 'cohesiveness', 'colleg', 'college', 'construct', 'construction', 'counten', 'countenance', 'crop', 'cultiv', 'cultivation', 'cultur', 'culture', 'danc', 'dance', 'dancing', 'deed', 'demolit', 'demolition', 'destruct', 'destruction', 'dig', 'digging', 'dimens', 'dimension', 'dissembl', 'dissemble', 'domest', 'domestic', 'domestic help', 'domesticated', 'domicil', 'domicile', 'domicili', 'domiciliate', 'dwell', 'dwelling', 'dwelling hous', 'dwelling house', 'electr', 'electric', 'electrical', 'excav', 'excavation', 'facebook', 'facil', 'facilities', 'facility', 'famili', 'family', 'fenc', 'fence', 'fence in', 'firearm', 'gun', 'gun for hir', 'gun for hire', 'gunman', 'gunsling', 'gunslinger', 'habit', 'habitation', 'health', 'health check', 'hemipterous insect', 'hire', 'hired gun', 'hit man', 'home', 'home bas', 'home pl', 'home plate', 'hous', 'house', 'house physician', 'house serv', 'house servant', 'household', 'housing', 'human act', 'human action', 'human activity', 'incom', 'income', 'indemn', 'indemnity', 'inebri', 'inebriant', 'inhabit', 'instagram', 'insur', 'insurance', 'insurance polici', 'insurance policy', 'intoxic', 'intoxicant', 'landlord', 'leisur', 'leisure', 'leisure tim', 'leisure time', 'licenc', 'licence', 'licens', 'license', 'lie in', 'live', 'livingaccommod', 'livingaccommodations', 'lodg', 'lodging', 'low-cost', 'low-pric', 'low-priced', 'mansion', 'master', 'medic', 'medical', 'medical checkup', 'medical exam', 'medical examin', 'medical examination', 'menag', 'menage', 'mental synthesi', 'mental synthesis', 'mentalhealth', 'nonmigratori', 'nonmigratory', 'nursing hom', 'nursing home', 'occup', 'occupant', 'occupi', 'occupier', 'offend', 'offender', 'palisad', 'palisade', 'pari', 'paries', 'permiss', 'permission', 'permit', 'planetary hous', 'planetary house', 'plate', 'playact', 'popul', 'populate', 'pro', 'probat', 'probation', 'profession', 'professional', 'professional person', 'properti', 'property', 'protect', 'protection', 'psycholog', 'psychology', 'put up', 'rampart', 'rent', 'renter', 'resid', 'residence', 'residency', 'resident', 'resident physician', 'residenti', 'residential', 'rest hom', 'rest home', 'roleplay', 'room', 'routin', 'routine', 'sceneri', 'scenery', 'secur', 'security', 'security depart', 'security department', 'security measur', 'security measure', 'security measures', 'security system', 'shooter', 'small-arm', 'snapchat', 'social media', 'structur', 'structure', 'studi', 'study', 'sureti', 'surety', 'surround', 'tenant', 'theatr', 'theatre', 'toler', 'tolerate', 'tourism', 'touristri', 'touristry', 'triggerman', 'univers', 'university', 'wall', 'welfar', 'welfare', 'well', 'wellness', 'wipeout', 'wiretap', 'workplac', 'workplace', 'wrongdoer']\r\n",
    "    \r\n",
    "    counter = 0\r\n",
    "    arrayno=[]\r\n",
    "    name = str(entry_field1.get())\r\n",
    "    name = textinitialpreprocess(name)\r\n",
    "    name_without_stopwords = remove_stopwords(name)\r\n",
    "\r\n",
    "    print(\"comparing name, name wout stopwords\", name, \"\\n\",name_without_stopwords )\r\n",
    "\r\n",
    "    for el in economy:\r\n",
    "        if el in name_without_stopwords or el in get_ekphrasis(name_without_stopwords) or el in spacy_lemmatizer(name_without_stopwords):\r\n",
    "            counter+=1\r\n",
    "            economyWordCount = economyWordCount + 1\r\n",
    "            dict_phrases['Smart Economy'] +=1\r\n",
    "            name_without_stopwords = name_without_stopwords.replace(el,'')            \r\n",
    "\r\n",
    "    for el in mobility:\r\n",
    "        if el in name_without_stopwords or el in get_ekphrasis(name_without_stopwords) or el in spacy_lemmatizer(name_without_stopwords):\r\n",
    "            counter+=1            \r\n",
    "            mobilityWordCount = mobilityWordCount + 1     \r\n",
    "            dict_phrases['Smart Mobility'] +=1  \r\n",
    "            name_without_stopwords = name_without_stopwords.replace(el,'')            \r\n",
    "\r\n",
    "    for el in environment:\r\n",
    "        if el in name_without_stopwords or el in get_ekphrasis(name_without_stopwords) or el in spacy_lemmatizer(name_without_stopwords):\r\n",
    "            counter+=1\r\n",
    "            environmentWordCount = environmentWordCount + 1     \r\n",
    "            dict_phrases['Smart Environment'] +=1  \r\n",
    "            name_without_stopwords = name_without_stopwords.replace(el,'') \r\n",
    "\r\n",
    "    for el in governance:\r\n",
    "        if el in name_without_stopwords or el in get_ekphrasis(name_without_stopwords) or el in spacy_lemmatizer(name_without_stopwords):\r\n",
    "            counter+=1\r\n",
    "            governanceWordCount = governanceWordCount + 1     \r\n",
    "            dict_phrases['Smart Governance'] +=1  \r\n",
    "            name_without_stopwords = name_without_stopwords.replace(el,'')\r\n",
    "\r\n",
    "    for el in living:\r\n",
    "        if el in name_without_stopwords or el in get_ekphrasis(name_without_stopwords) or el in spacy_lemmatizer(name_without_stopwords):\r\n",
    "            counter+=1\r\n",
    "            livingWordCount = livingWordCount + 1\r\n",
    "            dict_phrases['Smart Living'] +=1   \r\n",
    "            name_without_stopwords = name_without_stopwords.replace(el,'')\r\n",
    "\r\n",
    "    for el in people:\r\n",
    "        if el in name_without_stopwords or el in get_ekphrasis(name_without_stopwords) or el in spacy_lemmatizer(name_without_stopwords):\r\n",
    "            counter+=1\r\n",
    "            peopleWordCount = peopleWordCount + 1\r\n",
    "            dict_phrases['Smart People'] +=1   \r\n",
    "            name_without_stopwords = name_without_stopwords.replace(el,'')  \r\n",
    "    \r\n",
    "    if counter==0:\r\n",
    "        dict_phrases['No Matches'] +=1                         \r\n",
    "  \r\n",
    "    \r\n",
    "    if counter >0:\r\n",
    "        arrayno.append(counter)\r\n",
    "        for key in dict_phrases:\r\n",
    "            if dict_phrases[key] >0:\r\n",
    "                arrayno.append(key)\r\n",
    "                arrayno.append(dict_phrases[key])\r\n",
    "                \r\n",
    "                \r\n",
    "        for i in range(1,len(arrayno)):\r\n",
    "            if i %2==0:\r\n",
    "                arrayno[i]= '{:3.2f}'.format(arrayno[i]/counter*100)\r\n",
    "       \r\n",
    "        return arrayno\r\n",
    "    else:\r\n",
    "        arrayno.append(\"No Matches\")\r\n",
    "        return arrayno\r\n",
    "   \r\n",
    "\r\n",
    "def phrase_display():\r\n",
    "    greeting = phrase_generator()\r\n",
    "    \r\n",
    "    greeting_display= tk.Text(master=window,height =1, width=100,font=(\"Arial\", 10))\r\n",
    "    total = max(dict_phrases['Smart Economy'] + \\\r\n",
    "            dict_phrases['Smart Mobility'] + \\\r\n",
    "            dict_phrases['Smart Environment'] + \\\r\n",
    "            dict_phrases['Smart Governance'] + \\\r\n",
    "            dict_phrases['Smart People']+  \\\r\n",
    "            dict_phrases['Smart Living'],1)\r\n",
    "\r\n",
    "    Economy_per = \"{:.0%}\".format(dict_phrases['Smart Economy']/total)\r\n",
    "    Mobility_per = \"{:.0%}\".format(dict_phrases['Smart Mobility']/total)\r\n",
    "    Environment_per = \"{:.0%}\".format(dict_phrases['Smart Environment']/total)\r\n",
    "    Governance_per = \"{:.0%}\".format(dict_phrases['Smart Governance']/total)\r\n",
    "    People_per = \"{:.0%}\".format(dict_phrases['Smart People']/total)\r\n",
    "    Living_per = \"{:.0%}\".format(dict_phrases['Smart Living']/total)\r\n",
    "    \r\n",
    "    messagebox.showinfo(\"       Results of mapping\", \"Results:  \\n  \\\r\n",
    "                                Smart Economy: \\t \\t {} \\t {} \\n  \\\r\n",
    "                                Smart Mobility: \\t \\t {} \\t {} \\n  \\\r\n",
    "                                Smart Environment: \\t {} \\t {} \\n  \\\r\n",
    "                                Smart Governance: \\t {} \\t {} \\n  \\\r\n",
    "                                Smart People: \\t \\t {} \\t {} \\n  \\\r\n",
    "                                Smart Living: \\t \\t {} \\t {} \\n \".\r\n",
    "                                format(dict_phrases['Smart Economy'], Economy_per, \r\n",
    "                                        dict_phrases['Smart Mobility'], Mobility_per, \r\n",
    "                                        dict_phrases['Smart Environment'], Environment_per,\r\n",
    "                                        dict_phrases['Smart Governance'], Governance_per, \r\n",
    "                                        dict_phrases['Smart People'],People_per,\r\n",
    "                                        dict_phrases['Smart Living'], Living_per\r\n",
    "                                        \r\n",
    "                                        ))\r\n",
    "    total = 1\r\n",
    "    dict_phrases['Smart Economy'] = 0\r\n",
    "    dict_phrases['Smart Mobility'] =0\r\n",
    "    dict_phrases['Smart Environment'] =0\r\n",
    "    dict_phrases['Smart Governance'] =0\r\n",
    "    dict_phrases['Smart People'] = 0\r\n",
    "    dict_phrases['Smart Living'] = 0   \r\n",
    "\r\n",
    "button1 = tk.Button(text=\"Results \", command=phrase_display)\r\n",
    "button1.grid(column=1, row=4)\r\n",
    "window.mainloop()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "comparing name, name wout stopwords trash \n",
      " trash\n",
      "comparing name, name wout stopwords trash can \n",
      " trash\n",
      "comparing name, name wout stopwords trash bin \n",
      " trash bin\n",
      "comparing name, name wout stopwords trash dump \n",
      " trash dump\n",
      "comparing name, name wout stopwords trash can \n",
      " trash\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0993227984ad8824c264444a38e824e4c951a7592d518f6e93ecdb2b05867cef"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}